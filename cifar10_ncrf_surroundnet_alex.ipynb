{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from vonenet.utils import gabor_kernel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class GaborFilterBank(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, device, stride=4):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.stride = (stride, stride)\n",
    "        self.padding = (kernel_size // 2, kernel_size//2)\n",
    "\n",
    "        self.weight = torch.zeros((out_channels, in_channels, kernel_size, kernel_size)).to(device)\n",
    "        \n",
    "\n",
    "    def initialize(self, sf, theta, sigx, sigy, phase, seed=None):\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "        \n",
    "        random_channel = torch.randint(0, self.in_channels, (self.out_channels,))\n",
    "        for i in range(self.out_channels):\n",
    "            self.weight[i, random_channel[i]] = gabor_kernel(\n",
    "                frequency=sf[i], sigma_x=sigx[i], sigma_y=sigy[i],\n",
    "                theta=theta[i], offset=phase[i], ks=self.kernel_size[0]\n",
    "            )\n",
    "        self.weight = nn.Parameter(self.weight, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [256, 3, 15, 15] \n",
    "        #print(\"x\",x.shape, x.device)\n",
    "        #print(\"weight\", self.weight.shape, self.weight.device)\n",
    "        return F.conv2d(x, self.weight, None, stride=self.stride, padding=self.padding)\n",
    "\n",
    "class NCRFModule(nn.Module):\n",
    "    def __init__(self, gabor_bank, modulation_strength=0.5, surround_kernel_size=3):\n",
    "        super(NCRFModule, self).__init__()\n",
    "        self.gabor_bank = gabor_bank\n",
    "        self.modulation_strength = modulation_strength\n",
    "        self.surround_kernel_size = surround_kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"here\")\n",
    "        #center_response = self.gabor_bank(x)\n",
    "        #print(\"center_response\")\n",
    "        surround_response = F.avg_pool2d(\n",
    "            x, kernel_size=self.surround_kernel_size, stride=1, padding=self.surround_kernel_size // 2\n",
    "        ) * self.modulation_strength\n",
    "        modulated_response = x / (1 + surround_response)\n",
    "        return modulated_response\n",
    "\n",
    "class V1Processing(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=256, kernel_size=9, stride=4, noise_mode='neuronal', noise_level=0.07, noise_scale=0.35, device='cpu'):\n",
    "        super(V1Processing, self).__init__()\n",
    "        # self.gabor_bank = GaborFilterBank(in_channels, out_channels, kernel_size)\n",
    "        self.simple_conv_q0 = GaborFilterBank(in_channels, out_channels, kernel_size, device, stride)\n",
    "        self.simple_conv_q1 = GaborFilterBank(in_channels, out_channels, kernel_size, device, stride)\n",
    "        self.ncrf_q0 = NCRFModule(self.simple_conv_q0)\n",
    "        self.ncrf_q1 = NCRFModule(self.simple_conv_q1)\n",
    "        \n",
    "        # Simple and Complex Cells\n",
    "\n",
    "        # ---- FIX: Initialize Gabor filters with random parameters ----\n",
    "        sf    = torch.rand(out_channels) * 0.5 + 0.1    # frequencies between 0.1 and 0.6\n",
    "        theta = torch.rand(out_channels) * np.pi          # orientations between 0 and pi\n",
    "        sigx  = torch.rand(out_channels) * 2 + 1.0          # sigma between 1 and 3\n",
    "        sigy  = torch.rand(out_channels) * 2 + 1.0\n",
    "        phase = torch.rand(out_channels) * 2 * np.pi        # phase between 0 and 2pi\n",
    "        self.simple_conv_q0.initialize(sf, theta, sigx, sigy, phase)\n",
    "        self.simple_conv_q0.initialize(sf, theta, sigx, sigy, phase + np.pi/2)\n",
    "\n",
    "        self.simple = nn.ReLU()\n",
    "        self.complex = nn.Identity()\n",
    "        self.gabors = nn.Identity()\n",
    "        self.noise = nn.ReLU()\n",
    "        self.output = nn.Identity()\n",
    "        \n",
    "        # Noise settings (noise level reduced from 0.1 to 0.01)\n",
    "        self.noise_mode = noise_mode\n",
    "        self.noise_level = noise_level\n",
    "        self.noise_scale = noise_scale\n",
    "        self.fixed_noise = None\n",
    "        self.simple_channels = 128 \n",
    "        self.complex_channels = 128 \n",
    "        self.k_exc = 25\n",
    "\n",
    "\n",
    "    def set_noise_mode(self, mode='gaussian', level=0.01):\n",
    "        self.noise_mode = mode\n",
    "        self.noise_level = level\n",
    "\n",
    "    def fix_noise(self, batch_size, shape):\n",
    "        self.fixed_noise = torch.randn(batch_size, *shape, device=device) * self.noise_level\n",
    "    \n",
    "    def noise_f(self, x):\n",
    "        if self.noise_mode == 'gaussian':\n",
    "            return x + torch.randn_like(x) * self.noise_level\n",
    "        elif self.noise_mode == 'neuronal':\n",
    "            eps = 10e-5\n",
    "            x *= self.noise_scale\n",
    "            x += self.noise_level\n",
    "            if self.fixed_noise is not None:\n",
    "                x += self.fixed_noise * torch.sqrt(F.relu(x.clone()) + eps)\n",
    "            else:\n",
    "                x += torch.distributions.normal.Normal(torch.zeros_like(x), scale=1).rsample() * \\\n",
    "                     torch.sqrt(F.relu(x.clone()) + eps)\n",
    "            x -= self.noise_level\n",
    "            x /= self.noise_scale\n",
    "            return self.noise(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        s_q0 = self.ncrf_q0(self.simple_conv_q0(x))\n",
    "        s_q1 = self.ncrf_q1(self.simple_conv_q1(x))\n",
    "        c = self.complex(torch.sqrt(s_q0[:, self.simple_channels:, :, :] ** 2 +\n",
    "                                    s_q1[:, self.simple_channels:, :, :] ** 2) / np.sqrt(2))\n",
    "        s = self.simple(s_q0[:, 0:self.simple_channels, :, :])\n",
    "        response = self.gabors(self.k_exc * torch.cat((s, c), 1))\n",
    "        \n",
    "        simple_response = self.noise_f(response)\n",
    "        output = self.output(simple_response)\n",
    "        print(output.shape) # torch.Size([32, 3, 14, 14]) \n",
    "        return output\n",
    "        '''\n",
    "        #print(f\"Input shape: {x.shape}\")  # Print initial input shape\n",
    "        #print(self.simple_conv_q0)\n",
    "        #print(self.ncrf_q0)\n",
    "        s_q0 = self.simple_conv_q0(x)\n",
    "        #print(f\"Shape after simple_conv_q0 + NCRF: {s_q0.shape}\")\n",
    "    \n",
    "        s_q1 = self.simple_conv_q1(x)\n",
    "        #print(f\"Shape after simple_conv_q1 + NCRF: {s_q1.shape}\")\n",
    "    \n",
    "        c = self.complex(torch.sqrt(s_q0[:, self.simple_channels:, :, :] ** 2 +\n",
    "                                    s_q1[:, self.simple_channels:, :, :] ** 2) / np.sqrt(2))\n",
    "        #print(f\"Shape of complex cell response: {c.shape}\")\n",
    "    \n",
    "        s = self.simple(s_q0[:, 0:self.simple_channels, :, :])\n",
    "        #print(f\"Shape of simple cell response: {s.shape}\")\n",
    "    \n",
    "        response = self.gabors(self.k_exc * torch.cat((s, c), 1))\n",
    "        #print(f\"Shape after concatenating simple & complex responses: {response.shape}\")\n",
    "    \n",
    "        simple_response = self.noise_f(response)\n",
    "        #print(f\"Shape after noise function: {simple_response.shape}\")\n",
    "    \n",
    "        output = self.output(simple_response)\n",
    "        #print(f\"Final output shape: {output.shape}\")\n",
    "\n",
    "        output = self.ncrf_q0(simple_response)\n",
    "        #print(f\"Final1 output shape: {output.shape}\")\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm326/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "AlexNetBackEnd(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(64, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=12544, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "AlexNetWithGabor(\n",
      "  (model): Sequential(\n",
      "    (ncrf): V1Processing(\n",
      "      (simple_conv_q0): GaborFilterBank()\n",
      "      (simple_conv_q1): GaborFilterBank()\n",
      "      (ncrf_q0): NCRFModule(\n",
      "        (gabor_bank): GaborFilterBank()\n",
      "      )\n",
      "      (ncrf_q1): NCRFModule(\n",
      "        (gabor_bank): GaborFilterBank()\n",
      "      )\n",
      "      (simple): ReLU()\n",
      "      (complex): Identity()\n",
      "      (gabors): Identity()\n",
      "      (noise): ReLU()\n",
      "      (output): Identity()\n",
      "    )\n",
      "    (bottleneck): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (model): AlexNetBackEnd(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d(64, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "      (classifier): Sequential(\n",
      "        (0): Dropout(p=0.5, inplace=False)\n",
      "        (1): Linear(in_features=12544, out_features=4096, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "        (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import alexnet\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import custom Gabor filter bank and processing module from above\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "class AlexNetBackEnd(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AlexNetWithGabor(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super(AlexNetWithGabor, self).__init__()\n",
    "        gabor = V1Processing(in_channels, out_channels=256, kernel_size=15, stride=4, device='cuda:0').to(device)\n",
    "        bottleneck = nn.Conv2d(256, 64, kernel_size=1, stride=1, bias=False)\n",
    "        print(bottleneck)\n",
    "        nn.init.kaiming_normal_(bottleneck.weight, mode='fan_out', nonlinearity='relu')\n",
    "        #self.alexnet = alexnet(num_classes=num_classes).to(device)\n",
    "        \n",
    "        # Modify first layer to accept 64 Gabor channels instead of 3\n",
    "        #self.alexnet.features[0] = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        model_back_end = AlexNetBackEnd() \n",
    "        print(model_back_end)\n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('ncrf', gabor),\n",
    "            ('bottleneck',bottleneck),\n",
    "            ('model', model_back_end)\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "model = AlexNetWithGabor().to(device)\n",
    "print(model)\n",
    "#model= nn.DataParallel(model).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# ---- FIX: Lowered learning rate for Adam (from 0.1 to 1e-3) ----\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # ---- FIX: Gradient clipping to prevent exploding gradients ----\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "def test(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, trainloader, criterion, optimizer, epochs=30)\n",
    "test(model, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
