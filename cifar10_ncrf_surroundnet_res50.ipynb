{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from vonenet.utils import gabor_kernel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class GaborFilterBank(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, device, stride=4):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.stride = (stride, stride)\n",
    "        self.padding = (kernel_size // 2, kernel_size//2)\n",
    "\n",
    "        self.weight = torch.zeros((out_channels, in_channels, kernel_size, kernel_size)).to(device)\n",
    "        \n",
    "\n",
    "    def initialize(self, sf, theta, sigx, sigy, phase, seed=None):\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "        \n",
    "        random_channel = torch.randint(0, self.in_channels, (self.out_channels,))\n",
    "        for i in range(self.out_channels):\n",
    "            self.weight[i, random_channel[i]] = gabor_kernel(\n",
    "                frequency=sf[i], sigma_x=sigx[i], sigma_y=sigy[i],\n",
    "                theta=theta[i], offset=phase[i], ks=self.kernel_size[0]\n",
    "            )\n",
    "        self.weight = nn.Parameter(self.weight, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [256, 3, 15, 15] \n",
    "        #print(\"x\",x.shape, x.device)\n",
    "        #print(\"weight\", self.weight.shape, self.weight.device)\n",
    "        return F.conv2d(x, self.weight, None, stride=self.stride, padding=self.padding)\n",
    "\n",
    "class NCRFModule(nn.Module):\n",
    "    def __init__(self, gabor_bank, modulation_strength=0.5, surround_kernel_size=3):\n",
    "        super(NCRFModule, self).__init__()\n",
    "        self.gabor_bank = gabor_bank\n",
    "        self.modulation_strength = modulation_strength\n",
    "        self.surround_kernel_size = surround_kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"here\")\n",
    "        #center_response = self.gabor_bank(x)\n",
    "        #print(\"center_response\")\n",
    "        surround_response = F.avg_pool2d(\n",
    "            x, kernel_size=self.surround_kernel_size, stride=1, padding=self.surround_kernel_size // 2\n",
    "        ) * self.modulation_strength\n",
    "        modulated_response = x / (1 + surround_response)\n",
    "        return modulated_response\n",
    "\n",
    "class V1Processing(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=256, kernel_size=9, stride=4, noise_mode='neuronal', noise_level=0.07, noise_scale=0.35, device='cpu'):\n",
    "        super(V1Processing, self).__init__()\n",
    "        # self.gabor_bank = GaborFilterBank(in_channels, out_channels, kernel_size)\n",
    "        self.simple_conv_q0 = GaborFilterBank(in_channels, out_channels, kernel_size, device, stride)\n",
    "        self.simple_conv_q1 = GaborFilterBank(in_channels, out_channels, kernel_size, device, stride)\n",
    "        self.ncrf_q0 = NCRFModule(self.simple_conv_q0)\n",
    "        self.ncrf_q1 = NCRFModule(self.simple_conv_q1)\n",
    "        \n",
    "        # Simple and Complex Cells\n",
    "\n",
    "        # ---- FIX: Initialize Gabor filters with random parameters ----\n",
    "        sf    = torch.rand(out_channels) * 0.5 + 0.1    # frequencies between 0.1 and 0.6\n",
    "        theta = torch.rand(out_channels) * np.pi          # orientations between 0 and pi\n",
    "        sigx  = torch.rand(out_channels) * 2 + 1.0          # sigma between 1 and 3\n",
    "        sigy  = torch.rand(out_channels) * 2 + 1.0\n",
    "        phase = torch.rand(out_channels) * 2 * np.pi        # phase between 0 and 2pi\n",
    "        self.simple_conv_q0.initialize(sf, theta, sigx, sigy, phase)\n",
    "        self.simple_conv_q0.initialize(sf, theta, sigx, sigy, phase + np.pi/2)\n",
    "\n",
    "        self.simple = nn.ReLU()\n",
    "        self.complex = nn.Identity()\n",
    "        self.gabors = nn.Identity()\n",
    "        self.noise = nn.ReLU()\n",
    "        self.output = nn.Identity()\n",
    "        \n",
    "        # Noise settings (noise level reduced from 0.1 to 0.01)\n",
    "        self.noise_mode = noise_mode\n",
    "        self.noise_level = noise_level\n",
    "        self.noise_scale = noise_scale\n",
    "        self.fixed_noise = None\n",
    "        self.simple_channels = 128 \n",
    "        self.complex_channels = 128 \n",
    "        self.k_exc = 25\n",
    "\n",
    "\n",
    "    def set_noise_mode(self, mode='gaussian', level=0.01):\n",
    "        self.noise_mode = mode\n",
    "        self.noise_level = level\n",
    "\n",
    "    def fix_noise(self, batch_size, shape):\n",
    "        self.fixed_noise = torch.randn(batch_size, *shape, device=device) * self.noise_level\n",
    "    \n",
    "    def noise_f(self, x):\n",
    "        if self.noise_mode == 'gaussian':\n",
    "            return x + torch.randn_like(x) * self.noise_level\n",
    "        elif self.noise_mode == 'neuronal':\n",
    "            eps = 10e-5\n",
    "            x *= self.noise_scale\n",
    "            x += self.noise_level\n",
    "            if self.fixed_noise is not None:\n",
    "                x += self.fixed_noise * torch.sqrt(F.relu(x.clone()) + eps)\n",
    "            else:\n",
    "                x += torch.distributions.normal.Normal(torch.zeros_like(x), scale=1).rsample() * \\\n",
    "                     torch.sqrt(F.relu(x.clone()) + eps)\n",
    "            x -= self.noise_level\n",
    "            x /= self.noise_scale\n",
    "            return self.noise(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        s_q0 = self.ncrf_q0(self.simple_conv_q0(x))\n",
    "        s_q1 = self.ncrf_q1(self.simple_conv_q1(x))\n",
    "        c = self.complex(torch.sqrt(s_q0[:, self.simple_channels:, :, :] ** 2 +\n",
    "                                    s_q1[:, self.simple_channels:, :, :] ** 2) / np.sqrt(2))\n",
    "        s = self.simple(s_q0[:, 0:self.simple_channels, :, :])\n",
    "        response = self.gabors(self.k_exc * torch.cat((s, c), 1))\n",
    "        \n",
    "        simple_response = self.noise_f(response)\n",
    "        output = self.output(simple_response)\n",
    "        print(output.shape) # torch.Size([32, 3, 14, 14]) \n",
    "        return output\n",
    "        '''\n",
    "        #print(f\"Input shape: {x.shape}\")  # Print initial input shape\n",
    "        #print(self.simple_conv_q0)\n",
    "        #print(self.ncrf_q0)\n",
    "        s_q0 = self.simple_conv_q0(x)\n",
    "        #print(f\"Shape after simple_conv_q0 + NCRF: {s_q0.shape}\")\n",
    "    \n",
    "        s_q1 = self.simple_conv_q1(x)\n",
    "        #print(f\"Shape after simple_conv_q1 + NCRF: {s_q1.shape}\")\n",
    "    \n",
    "        c = self.complex(torch.sqrt(s_q0[:, self.simple_channels:, :, :] ** 2 +\n",
    "                                    s_q1[:, self.simple_channels:, :, :] ** 2) / np.sqrt(2))\n",
    "        #print(f\"Shape of complex cell response: {c.shape}\")\n",
    "    \n",
    "        s = self.simple(s_q0[:, 0:self.simple_channels, :, :])\n",
    "        #print(f\"Shape of simple cell response: {s.shape}\")\n",
    "    \n",
    "        response = self.gabors(self.k_exc * torch.cat((s, c), 1))\n",
    "        #print(f\"Shape after concatenating simple & complex responses: {response.shape}\")\n",
    "    \n",
    "        simple_response = self.noise_f(response)\n",
    "        #print(f\"Shape after noise function: {simple_response.shape}\")\n",
    "    \n",
    "        output = self.output(simple_response)\n",
    "        #print(f\"Final output shape: {output.shape}\")\n",
    "\n",
    "        output = self.ncrf_q0(simple_response)\n",
    "        #print(f\"Final1 output shape: {output.shape}\")\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm326/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "ResNetBackEnd(\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "ResNetWithGabor(\n",
      "  (model): Sequential(\n",
      "    (ncrf): V1Processing(\n",
      "      (simple_conv_q0): GaborFilterBank()\n",
      "      (simple_conv_q1): GaborFilterBank()\n",
      "      (ncrf_q0): NCRFModule(\n",
      "        (gabor_bank): GaborFilterBank()\n",
      "      )\n",
      "      (ncrf_q1): NCRFModule(\n",
      "        (gabor_bank): GaborFilterBank()\n",
      "      )\n",
      "      (simple): ReLU()\n",
      "      (complex): Identity()\n",
      "      (gabors): Identity()\n",
      "      (noise): ReLU()\n",
      "      (output): Identity()\n",
      "    )\n",
      "    (bottleneck): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (model): ResNetBackEnd(\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import alexnet\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import custom Gabor filter bank and processing module from above\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True) #\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True) # inplace=True\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetBackEnd(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNetBackEnd, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "class ResNetWithGabor(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super(ResNetWithGabor, self).__init__()\n",
    "        gabor = V1Processing(in_channels, out_channels=256, kernel_size=15, stride=4, device='cuda:0').to(device)\n",
    "        bottleneck = nn.Conv2d(256, 64, kernel_size=1, stride=1, bias=False)\n",
    "        print(bottleneck)\n",
    "        nn.init.kaiming_normal_(bottleneck.weight, mode='fan_out', nonlinearity='relu')\n",
    "        #self.alexnet = alexnet(num_classes=num_classes).to(device)\n",
    "        \n",
    "        # Modify first layer to accept 64 Gabor channels instead of 3\n",
    "        #self.alexnet.features[0] = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        model_back_end = ResNetBackEnd(block=Bottleneck, layers=[3, 4, 6, 3])\n",
    "        #model_back_end = ResNetBackEnd() \n",
    "        print(model_back_end)\n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('ncrf', gabor),\n",
    "            ('bottleneck',bottleneck),\n",
    "            ('model', model_back_end)\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "model = ResNetWithGabor().to(device)\n",
    "print(model)\n",
    "#model= nn.DataParallel(model).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# ---- FIX: Lowered learning rate for Adam (from 0.1 to 1e-3) ----\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # ---- FIX: Gradient clipping to prevent exploding gradients ----\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "def test(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"aniso_res50_cifar10_10_new.pth\")\n",
    "#model.load_state_dict(torch.load(\"aniso_res50_cifar10_10_new.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1604\n",
      "Epoch 2/10, Loss: 0.1090\n",
      "Epoch 3/10, Loss: 0.0877\n",
      "Epoch 4/10, Loss: 0.0814\n",
      "Epoch 5/10, Loss: 0.0675\n",
      "Epoch 6/10, Loss: 0.0645\n",
      "Epoch 7/10, Loss: 0.0602\n",
      "Epoch 8/10, Loss: 0.0513\n",
      "Epoch 9/10, Loss: 0.0506\n",
      "Epoch 10/10, Loss: 0.0531\n",
      "Test Accuracy: 77.91%\n"
     ]
    }
   ],
   "source": [
    "train(model, trainloader, criterion, optimizer, epochs=10)\n",
    "test(model, testloader)\n",
    "#torch.save(model.state_dict(), \"alexnet_gabor_cifar10.pth\")\n",
    "#print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.0174\n",
      "Epoch 2/30, Loss: 0.0157\n",
      "Epoch 3/30, Loss: 0.0191\n",
      "Epoch 4/30, Loss: 0.0159\n",
      "Epoch 5/30, Loss: 0.0193\n",
      "Epoch 6/30, Loss: 0.0131\n",
      "Epoch 7/30, Loss: 0.0200\n",
      "Epoch 8/30, Loss: 0.0127\n",
      "Epoch 9/30, Loss: 0.0176\n",
      "Epoch 10/30, Loss: 0.0179\n",
      "Epoch 11/30, Loss: 0.0140\n",
      "Epoch 12/30, Loss: 0.0183\n",
      "Epoch 13/30, Loss: 0.0140\n",
      "Epoch 14/30, Loss: 0.0148\n",
      "Epoch 15/30, Loss: 0.0167\n",
      "Epoch 16/30, Loss: 0.0145\n",
      "Epoch 17/30, Loss: 0.0127\n",
      "Epoch 18/30, Loss: 0.0140\n",
      "Epoch 19/30, Loss: 0.0156\n",
      "Epoch 20/30, Loss: 0.0169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test(model, testloader)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#torch.save(model.state_dict(), \"alexnet_gabor_cifar10.pth\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#print(\"Model saved successfully!\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 244\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m    242\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mcuda(), labels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    243\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 244\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    246\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 227\u001b[0m, in \u001b[0;36mResNetWithGabor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 227\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 150\u001b[0m, in \u001b[0;36mV1Processing.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgabors(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_exc \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((s, c), \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#print(f\"Shape after concatenating simple & complex responses: {response.shape}\")\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m simple_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoise_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m#print(f\"Shape after noise function: {simple_response.shape}\")\u001b[39;00m\n\u001b[1;32m    153\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(simple_response)\n",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m, in \u001b[0;36mV1Processing.noise_f\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_noise \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(F\u001b[38;5;241m.\u001b[39mrelu(x\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;241m+\u001b[39m eps)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrsample() \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m    110\u001b[0m          torch\u001b[38;5;241m.\u001b[39msqrt(F\u001b[38;5;241m.\u001b[39mrelu(x\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;241m+\u001b[39m eps)\n\u001b[1;32m    111\u001b[0m x \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_level\n\u001b[1;32m    112\u001b[0m x \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_scale\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/normal.py:51\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc, scale, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[43mbroadcast_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, Number) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scale, Number):\n\u001b[1;32m     53\u001b[0m         batch_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/utils.py:39\u001b[0m, in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     37\u001b[0m             options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(v) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     40\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mnew_values)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mvalues)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/utils.py:39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m             options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(v) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mnew_values)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mvalues)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, trainloader, criterion, optimizer, epochs=30)\n",
    "test(model, testloader)\n",
    "#torch.save(model.state_dict(), \"alexnet_gabor_cifar10.pth\")\n",
    "#print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "1000\n",
      "Test Accuracy 0.808 CW Accuracy - 0.1 : 0.0000 - 0.01 : 0.5380 - 0.001 : 0.7830\n",
      "Test Accuracy 0.808 PG Accuracy - 0.1 : 0.4030 - 0.01 : 0.4210 - 0.001 : 0.4520\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the random seed\n",
    "seed = 42\n",
    "\n",
    "# Set seed for random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If using GPU, ensure deterministic behavior (optional)\n",
    "torch.cuda.manual_seed(seed)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "subset_indices = list(range(1000))  # First 1000 samples\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# Create a subset\n",
    "import random\n",
    "\n",
    "random_indices = random.sample(range(5000), 1000)\n",
    "#print(random_indices)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# Create a subset\n",
    "subset_dataset = Subset(testset, random_indices)\n",
    "\n",
    "print(len(subset_dataset))\n",
    "test_loader = torch.utils.data.DataLoader(subset_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "testloader = test_loader\n",
    "\n",
    "loss, acc = evaluate_model_test(model, testloader, device)\n",
    "pgd_1e3 = pgd_evaluate(model, testloader, device, eps=0.001)\n",
    "pgd_1e2 = pgd_evaluate(model, testloader, device, eps=0.01)\n",
    "pgd_1e1 = pgd_evaluate(model, testloader, device, eps=0.1)\n",
    "cw_1e3 = cw_evaluate(model, testloader, device, c=0.001)\n",
    "cw_1e2 = cw_evaluate(model, testloader, device, c=0.01)\n",
    "cw_1e1 = cw_evaluate(model, testloader, device, c=0.1)\n",
    "print(f\"Test Accuracy\",acc, f\"CW Accuracy - 0.1 : {cw_1e1:.4f} - 0.01 : {cw_1e2:.4f} - 0.001 : {cw_1e3:.4f}\")\n",
    "print(f\"Test Accuracy\",acc, f\"PG Accuracy - 0.1 : {pgd_1e1:.4f} - 0.01 : {pgd_1e2:.4f} - 0.001 : {pgd_1e3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "1000\n",
      "Test Accuracy 0.788 CW Accuracy - 0.1 : 0.0000 - 0.01 : 0.4670 - 0.001 : 0.7650\n",
      "Test Accuracy 0.788 PG Accuracy - 0.1 : 0.3560 - 0.01 : 0.3820 - 0.001 : 0.3890\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the random seed\n",
    "seed = 42\n",
    "\n",
    "# Set seed for random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# If using GPU, ensure deterministic behavior (optional)\n",
    "torch.cuda.manual_seed(seed)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "subset_indices = list(range(1000))  # First 1000 samples\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# Create a subset\n",
    "import random\n",
    "\n",
    "random_indices = random.sample(range(5000), 1000)\n",
    "#print(random_indices)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# Create a subset\n",
    "subset_dataset = Subset(testset, random_indices)\n",
    "\n",
    "print(len(subset_dataset))\n",
    "test_loader = torch.utils.data.DataLoader(subset_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "testloader = test_loader\n",
    "\n",
    "loss, acc = evaluate_model_test(model, testloader, device)\n",
    "pgd_1e3 = pgd_evaluate(model, testloader, device, eps=0.001)\n",
    "pgd_1e2 = pgd_evaluate(model, testloader, device, eps=0.01)\n",
    "pgd_1e1 = pgd_evaluate(model, testloader, device, eps=0.1)\n",
    "cw_1e3 = cw_evaluate(model, testloader, device, c=0.001)\n",
    "cw_1e2 = cw_evaluate(model, testloader, device, c=0.01)\n",
    "cw_1e1 = cw_evaluate(model, testloader, device, c=0.1)\n",
    "print(f\"Test Accuracy\",acc, f\"CW Accuracy - 0.1 : {cw_1e1:.4f} - 0.01 : {cw_1e2:.4f} - 0.001 : {cw_1e3:.4f}\")\n",
    "print(f\"Test Accuracy\",acc, f\"PG Accuracy - 0.1 : {pgd_1e1:.4f} - 0.01 : {pgd_1e2:.4f} - 0.001 : {pgd_1e3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import vonenet\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import logging\n",
    "import wandb\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils import load_and_prepare_v1_model, train_model, evaluate_model, initialize_wandb, pgd_attack, load_and_prepare_model\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD, L1FMNAttack, L2FMNAttack, L0FMNAttack, L2PGD\n",
    "import eagerpy as ep\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "batch_size = 1\n",
    "num_epochs_face = 500\n",
    "num_epochs_object = 50\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.filter(ImageFilter.GaussianBlur(self.sigma))\n",
    "\n",
    "def get_dataloader(blur_level, batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Lambda(lambda img: GaussianBlur(blur_level)(img)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    return trainloader\n",
    "def adjust_blur_and_train(task_type, model, criterion, optimizer, test_loader, batch_size, device, scheduler):\n",
    "    if task_type == 'face':\n",
    "        blur_levels = [8, 4, 2, 1, 0]\n",
    "        epochs_per_blur = 100\n",
    "        total_epochs = num_epochs_face\n",
    "    elif task_type == 'object':\n",
    "        blur_levels = [8, 4, 2, 1, 0]\n",
    "        epochs_per_blur = 10\n",
    "        total_epochs = num_epochs_object\n",
    "    else:\n",
    "        raise ValueError(\"Task type must be 'face' or 'object'\")\n",
    "\n",
    "    current_epoch = 0\n",
    "    i = 0 \n",
    "    for blur in blur_levels:\n",
    "        if current_epoch >= total_epochs:\n",
    "            break\n",
    "        epochs_to_train = min(epochs_per_blur, total_epochs - current_epoch)\n",
    "        train_loader = get_dataloader(blur, batch_size)\n",
    "        \n",
    "        if(i==0):\n",
    "            model, acc = train_model(model, criterion, optimizer, train_loader, test_loader, device, scheduler, num_epochs=10, patience=5)\n",
    "            #torch.save(model.state_dict(), \"model_inference_im100\"+str(blur)+\".pth\")\n",
    "            #old_params = {name: param.clone() for name, param in model.named_parameters()}\n",
    "            #fisher_information = compute_fisher_information(model, train_loader, criterion)\n",
    "        else:\n",
    "            model, acc = train_model(model, criterion, optimizer, train_loader, test_loader, device, scheduler, num_epochs=10, patience=5)\n",
    "            #torch.save(model.state_dict(), \"model_inference_im100\"+str(blur)+\".pth\")\n",
    "            #old_params = {name: param.clone() for name, param in model.named_parameters()}\n",
    "            #fisher_information = compute_fisher_information(model, train_loader, criterion)\n",
    "        \n",
    "        i+=1\n",
    "        current_epoch += epochs_to_train\n",
    "        \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wshi4npy) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae755a3f28640698ed44966951ae981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.027 MB uploaded\\r'), FloatProgress(value=0.28814648249277225, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>2.30328</td></tr><tr><td>test_accuracy</td><td>0.1</td></tr><tr><td>test_loss</td><td>nan</td></tr><tr><td>val_loss</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-water-25</strong> at: <a href='https://wandb.ai/ehsanmohd_/alex-b2c-cifar10/runs/wshi4npy' target=\"_blank\">https://wandb.ai/ehsanmohd_/alex-b2c-cifar10/runs/wshi4npy</a><br/> View project at: <a href='https://wandb.ai/ehsanmohd_/alex-b2c-cifar10' target=\"_blank\">https://wandb.ai/ehsanmohd_/alex-b2c-cifar10</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250212_233254-wshi4npy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wshi4npy). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mrahm326/experiments/BI-AI/For_NIPS/Experiments on MNIST/CIFAR10_Models/Adv_Explanation/wandb/run-20250213_000558-e851vnuv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ehsanmohd_/alex-b2c-cifar10/runs/e851vnuv' target=\"_blank\">sandy-river-26</a></strong> to <a href='https://wandb.ai/ehsanmohd_/alex-b2c-cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ehsanmohd_/alex-b2c-cifar10' target=\"_blank\">https://wandb.ai/ehsanmohd_/alex-b2c-cifar10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ehsanmohd_/alex-b2c-cifar10/runs/e851vnuv' target=\"_blank\">https://wandb.ai/ehsanmohd_/alex-b2c-cifar10/runs/e851vnuv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Starting training\n",
      "Epoch 1/10, Loss: 2.3033\n",
      "Epoch 1/10, Loss: 2.3033\n",
      "Test Loss: 2.3026, Test Accuracy: 0.1000\n",
      "Test Loss: 2.3026, Test Accuracy: 0.1000\n",
      "Epoch 1/10, Validation Loss: 2.3026\n",
      "Epoch 2/10, Loss: 2.3028\n",
      "Epoch 2/10, Loss: 2.3028\n",
      "Test Loss: nan, Test Accuracy: 0.1000\n",
      "Test Loss: nan, Test Accuracy: 0.1000\n",
      "Epoch 2/10, Validation Loss: nan\n",
      "NaN detected in loss\n",
      "NaN detected in loss\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     37\u001b[0m task_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 38\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43madjust_blur_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m val_loss, acc \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, device)\n\u001b[1;32m     40\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[7], line 148\u001b[0m, in \u001b[0;36madjust_blur_and_train\u001b[0;34m(task_type, model, criterion, optimizer, test_loader, batch_size, device, scheduler)\u001b[0m\n\u001b[1;32m    145\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m get_dataloader(blur, batch_size)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#print(next(train_loader))\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#def train_model(model, criterion, optimizer, train_loader, test_loader, device, scheduler, num_epochs=5, patience=5):\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m model, acc \u001b[38;5;241m=\u001b[39m train_model(model, criterion, optimizer, train_loader, test_loader, device, scheduler, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m#model, acc = train_model(model, train_loader, criterion, optimizer, epochs_to_train, device)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#torch.save(model.state_dict(), \"model_inference\"+str(blur)+\".pth\")\u001b[39;00m\n\u001b[1;32m    151\u001b[0m current_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m epochs_to_train\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "optimizer_name = 'sgd'\n",
    "learning_schedule = 'step'\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "project_name = \"alex-b2c-cifar10\"\n",
    "initialize_wandb(project_name, {\n",
    "        'dataset': 'cifar10',\n",
    "        'architecture': 'alex',\n",
    "        'epochs': 20,\n",
    "        'patience': 5\n",
    "})\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Define the learning rate schedule\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < 30:\n",
    "        return 1.0\n",
    "    elif epoch < 70:\n",
    "        return 0.1\n",
    "    elif epoch < 90:\n",
    "        return 0.01\n",
    "    elif epoch < 120:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0005\n",
    "\n",
    "if learning_schedule == 'step':\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "elif learning_schedule == 'linear':\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1 - epoch / 100)\n",
    "elif learning_schedule == 'exponential':\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "task_type = 'object'\n",
    "model = AlexNetWithGabor().to(device)\n",
    "print(model)\n",
    "\n",
    "model = adjust_blur_and_train(task_type, model, criterion, optimizer, test_loader, batch_size, device, scheduler)\n",
    "val_loss, acc = evaluate_model(model, test_loader, device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "#subset_indices = list(range(1000))  # First 1000 samples\n",
    "#from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# Create a subset\n",
    "#subset_dataset = Subset(testset, subset_indices)\n",
    "#print(len(subset_dataset))\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "testloader = test_loader\n",
    "\n",
    "loss, acc = evaluate_model_test(model, testloader, device)\n",
    "pgd_1e3 = pgd_evaluate(model, testloader, device, eps=0.001)\n",
    "pgd_1e2 = pgd_evaluate(model, testloader, device, eps=0.01)\n",
    "pgd_1e1 = pgd_evaluate(model, testloader, device, eps=0.1)\n",
    "cw_1e3 = cw_evaluate(model, testloader, device, c=0.001)\n",
    "cw_1e2 = cw_evaluate(model, testloader, device, c=0.01)\n",
    "cw_1e1 = cw_evaluate(model, testloader, device, c=0.1)\n",
    "print(f\"Test Accuracy\",acc, f\"CW Accuracy - 0.1 : {cw_1e1:.4f} - 0.01 : {cw_1e2:.4f} - 0.001 : {cw_1e3:.4f}\")\n",
    "print(f\"Test Accuracy\",acc, f\"PG Accuracy - 0.1 : {pgd_1e1:.4f} - 0.01 : {pgd_1e2:.4f} - 0.001 : {pgd_1e3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization with Optuna\n",
    "import optuna  \n",
    "\n",
    "def get_dataloaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return trainloader, testloader\n",
    "\n",
    "def train_and_evaluate(trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    \n",
    "    trainloader, testloader = get_dataloaders(batch_size)\n",
    "    model = AlexNetWithGabor().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(5):  # Limit training epochs for optimization\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "    \n",
    "    test(model, testloader)\n",
    "    # Return test accuracy as the optimization metric\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run hyperparameter optimization:\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(train_and_evaluate, n_trials=20)\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
